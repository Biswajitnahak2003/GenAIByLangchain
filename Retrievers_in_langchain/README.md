# ğŸ“Œ What are Retrievers?

Retrievers are a core component in LangChain that fetch relevant documents from a data source in response to a user's query. This enables Large Language Models (LLMs) to generate accurate, grounded responses based on external knowledge, not just what they were trained on.

## ğŸ“š Table of Contents
### ğŸ”¹ Based on Data Source
    ğŸŒ Vector Store Retriever
    ğŸ“š Wikipedia Retriever

### ğŸ”¹ Based on Retrieval Strategy
    âœ¨ Maximum Marginal Relevance (MMR) Retriever
    â“ Multi-Query Retriever
    ğŸ¯ Contextual Compression Retriever


## âš™ï¸ Setup

### Install Required Libraries:
```python
    pip install langchain-google-genai langchain-community faiss-cpu wikipedia langchain-cohere
```
### Set API Keys:

    Ensure GOOGLE_API_KEY is set in your environment, e.g., in a .env file or through Colab secrets.

## ğŸŒ Vector Store Retriever

The most common retriever. Performs a similarity search over a vectorized collection of your documents.

### Example:
 ```
from langchain_community.vectorstores import FAISS

db = FAISS.from_texts(
    ["Paris is in France.", "London is in England."],
    embedding_function
)
retriever = db.as_retriever()
retriever.invoke("Which city is in France?")
 ```
## ğŸ“š Wikipedia Retriever

Fetches documents directly from Wikipedia, acting as a real-time general-knowledge retriever.

### Example:
 ```
from langchain_community.retrievers import WikipediaRetriever

retriever = WikipediaRetriever(top_k_results=1)
retriever.invoke("Srinivasa Ramanujan")
 ```
## âœ¨ Maximum Marginal Relevance (MMR) Retriever

Returns results that are both relevant and diverse, avoiding repetition in search results.

### Example:
 ```
retriever = db.as_retriever(search_type="mmr")
retriever.invoke("Tell me about fruits.")
 ```
## â“ Multi-Query Retriever

Uses an LLM to reformulate the query in multiple ways for better coverage and recall.

### Example:
 ```
from langchain.retrievers.multi_query import MultiQueryRetriever

mq_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)
mq_retriever.invoke("What is there to do in New York City?")
 ```
## ğŸ¯ Contextual Compression Retriever

First retrieves documents, then filters them using a compressor (like rerankers) to keep only the most relevant snippets.

### Example:
 ```
from langchain.retrievers import ContextualCompressionRetriever
from langchain_cohere import CohereRerank

compressor = CohereRerank()
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=base_retriever
)
compression_retriever.invoke("What year was the first iPhone released?")
 ```
# ğŸ“Œ References
- [ğŸ“š LangChain Docs](https://docs.langchain.com/)
- [ğŸ” Retrievers in LangChain](https://docs.langchain.com/docs/modules/data_connection/retrievers/)
#  Author

    Biswajit Nahak
    BTech | ETC | @IIIT BBSR
